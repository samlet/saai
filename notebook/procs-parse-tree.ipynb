{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T06:14:02.585890Z",
     "start_time": "2020-04-05T06:14:00.073807Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root: estamos(estar; we're, verb, 2)\n",
      "├── punct: .(_, punct, 6)\n",
      "├── nsubj: Nosotros(yo; We, pron, 1)\n",
      "└── obl: escuela(escuela; school, noun, 5)\n",
      "    ├── det: la(el; the, det, 4)\n",
      "    └── case: en(en; in, adp, 3)\n"
     ]
    }
   ],
   "source": [
    "from sagas.nlu.nlu_tools import vis_tree\n",
    "from sagas.nlu.ruleset_procs import cached_chunks\n",
    "chunks = cached_chunks('Nosotros estamos en la escuela.',\n",
    "                       source='es',\n",
    "                       engine='stanza')\n",
    "ds=chunks['root_domains'][0]\n",
    "vis_tree(ds, 'es', trans=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T06:14:02.623484Z",
     "start_time": "2020-04-05T06:14:02.594090Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'index': 1,\n",
       "  'text': 'Nosotros',\n",
       "  'lemma': 'yo',\n",
       "  'upos': 'PRON',\n",
       "  'xpos': 'PRON',\n",
       "  'feats': 'Case=Acc,Nom|Gender=Masc|Number=Plur|Person=1|PronType=Prs',\n",
       "  'governor': 2,\n",
       "  'dependency_relation': 'nsubj',\n",
       "  'entity': ['O'],\n",
       "  'segments': []},\n",
       " {'index': 2,\n",
       "  'text': 'estamos',\n",
       "  'lemma': 'estar',\n",
       "  'upos': 'VERB',\n",
       "  'xpos': 'VERB',\n",
       "  'feats': 'Mood=Ind|Number=Plur|Person=1|Tense=Pres|VerbForm=Fin',\n",
       "  'governor': 0,\n",
       "  'dependency_relation': 'root',\n",
       "  'entity': ['O'],\n",
       "  'segments': []},\n",
       " {'index': 3,\n",
       "  'text': 'en',\n",
       "  'lemma': 'en',\n",
       "  'upos': 'ADP',\n",
       "  'xpos': 'ADP',\n",
       "  'feats': 'AdpType=Prep',\n",
       "  'governor': 5,\n",
       "  'dependency_relation': 'case',\n",
       "  'entity': ['O'],\n",
       "  'segments': []},\n",
       " {'index': 4,\n",
       "  'text': 'la',\n",
       "  'lemma': 'el',\n",
       "  'upos': 'DET',\n",
       "  'xpos': 'DET',\n",
       "  'feats': 'Definite=Def|Gender=Fem|Number=Sing|PronType=Art',\n",
       "  'governor': 5,\n",
       "  'dependency_relation': 'det',\n",
       "  'entity': ['O'],\n",
       "  'segments': []},\n",
       " {'index': 5,\n",
       "  'text': 'escuela',\n",
       "  'lemma': 'escuela',\n",
       "  'upos': 'NOUN',\n",
       "  'xpos': 'NOUN',\n",
       "  'feats': 'Gender=Fem|Number=Sing',\n",
       "  'governor': 2,\n",
       "  'dependency_relation': 'obl',\n",
       "  'entity': ['O'],\n",
       "  'segments': []},\n",
       " {'index': 6,\n",
       "  'text': '.',\n",
       "  'lemma': '.',\n",
       "  'upos': 'PUNCT',\n",
       "  'xpos': 'PUNCT',\n",
       "  'feats': 'PunctType=Peri',\n",
       "  'governor': 2,\n",
       "  'dependency_relation': 'punct',\n",
       "  'entity': ['O'],\n",
       "  'segments': []}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks['doc'].as_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T06:14:02.656265Z",
     "start_time": "2020-04-05T06:14:02.628137Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnalNode(dependency_relation='nsubj', entity=['O'], feats={'Case': 'Acc,Nom', 'Gender': 'Masc', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}, governor=2, index=1, lemma='yo', name='nsubj', segments=[], text='Nosotros', tok=<JsonifyWordImpl index=1;text=Nosotros;lemma=yo;upos=PRON;xpos=PRON;feats=Case=Acc,Nom|Gender=Masc|Number=Plur|Person=1|PronType=Prs;governor=2;dependency_relation=nsubj>, upos='PRON', xpos='PRON')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from anytree.node.nodemixin import NodeMixin\n",
    "from anytree.node.util import _repr\n",
    "from sagas.nlu.uni_intf import SentenceIntf, WordIntf, RootWordImpl\n",
    "from sagas.nlu.features import feats_map\n",
    "class Token(object):\n",
    "    def __init__(self, tok:WordIntf):\n",
    "        self.tok=tok        \n",
    "        self.name=tok.dependency_relation if tok is not None else '_'\n",
    "class AnalNode(NodeMixin, Token):\n",
    "    def __init__(self, tok, parent=None, children=None, **kwargs):\n",
    "        super(AnalNode, self).__init__(tok)\n",
    "        self.__dict__.update(kwargs)\n",
    "        if tok:\n",
    "            self.__dict__.update(tok.ctx)\n",
    "            self.feats=feats_map(tok.feats)\n",
    "        self.parent = parent\n",
    "        if children:\n",
    "            self.children = children\n",
    "\n",
    "    def __repr__(self):\n",
    "        return _repr(self)\n",
    "\n",
    "words=chunks['doc'].words\n",
    "root = AnalNode(words[0])\n",
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T06:14:02.710132Z",
     "start_time": "2020-04-05T06:14:02.661255Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root: estamos\n",
      "|-- nsubj: Nosotros\n",
      "|-- obl: escuela\n",
      "|   |-- case: en\n",
      "|   +-- det: la\n",
      "+-- punct: .\n"
     ]
    }
   ],
   "source": [
    "from anytree import Node, RenderTree, AsciiStyle, Walker, Resolver\n",
    "\n",
    "node_map={word.index:AnalNode(word) for word in words}\n",
    "node_map[0]=AnalNode(None)\n",
    "tree_root=next(w for w in node_map.values() if w.governor==0)\n",
    "def set_parent(w):\n",
    "    if w.tok:\n",
    "        w.parent=node_map[w.tok.governor]\n",
    "list(map(set_parent, node_map.values()))\n",
    "# print(RenderTree(tree_root, style=AsciiStyle()).by_attr('name'))\n",
    "print(RenderTree(tree_root, style=AsciiStyle()).by_attr(lambda n: f\"{n.dependency_relation}: {n.text}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T06:14:02.748020Z",
     "start_time": "2020-04-05T06:14:02.717564Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(AnalNode(dependency_relation='root', entity=['O'], feats={'Mood': 'Ind', 'Number': 'Plur', 'Person': '1', 'Tense': 'Pres', 'VerbForm': 'Fin'}, governor=0, index=2, lemma='estar', name='root', segments=[], text='estamos', tok=<JsonifyWordImpl index=2;text=estamos;lemma=estar;upos=VERB;xpos=VERB;feats=Mood=Ind|Number=Plur|Person=1|Tense=Pres|VerbForm=Fin;governor=0;dependency_relation=root>, upos='VERB', xpos='VERB'),)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from anytree.search import findall, findall_by_attr\n",
    "words=findall_by_attr(tree_root, name='upos', value='VERB')\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T06:14:02.777081Z",
     "start_time": "2020-04-05T06:14:02.762478Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pres_1_Plur\n"
     ]
    }
   ],
   "source": [
    "word=words[0]\n",
    "if 'Person' in word.feats:\n",
    "    personal=word.feats['Tense']+'_'+word.feats['Person']+'_'+word.feats['Number']\n",
    "    print(personal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T06:14:06.726080Z",
     "start_time": "2020-04-05T06:14:02.783552Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root: sleeps (sleep, verb)\n",
      "|-- nsubj: she (she, pron)\n",
      "|-- obl: bed (bed, noun)\n",
      "|   |-- case: on (on, adp)\n",
      "|   |-- det: the (the, det)\n",
      "|   +-- amod: green (green, adj)\n",
      "+-- punct: . (., punct)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('sleeps', False, True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagas.nlu.anal import build_anal_tree\n",
    "from anytree.search import findall, findall_by_attr\n",
    "\n",
    "sents='she sleeps on the green bed'\n",
    "lang='en'\n",
    "engine='stanza'\n",
    "\n",
    "f=build_anal_tree(sents, lang, engine)\n",
    "# f.verbs\n",
    "# f.rels('nsubj')\n",
    "f.draw()\n",
    "f.verbs[0].text, f.verbs[0].is_cat('physical_condition', '~'), \\\n",
    "    f.verbs[0].is_cat('physical_condition', 'n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T06:14:06.745843Z",
     "start_time": "2020-04-05T06:14:06.731668Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sleep'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.verbs[0].axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T06:14:06.764199Z",
     "start_time": "2020-04-05T06:14:06.751619Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnalNode(dependency_relation='amod', entity=['O'], feats={'Degree': 'Pos'}, governor=6, index=5, lang='en', lemma='green', name='amod', segments=[], text='green', tok=<JsonifyWordImpl index=5;text=green;lemma=green;upos=ADJ;xpos=JJ;feats=Degree=Pos;governor=6;dependency_relation=amod>, upos='ADJ', xpos='JJ')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from anytree import Node, RenderTree, AsciiStyle, Walker, Resolver\n",
    "r = Resolver('dependency_relation')\n",
    "r.get(f, \"./obl/amod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T06:14:06.879278Z",
     "start_time": "2020-04-05T06:14:06.772048Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root: estudiamos (estudiar, verb)\n",
      "|-- nsubj: Nosotros (yo, pron)\n",
      "|-- obj: francés (francés, noun)\n",
      "+-- punct: . (., punct)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('estudiamos', True, 'study')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagas.nlu.anal import build_anal_tree\n",
    "from anytree.search import findall, findall_by_attr\n",
    "f=build_anal_tree('Nosotros estudiamos francés.', 'es', 'stanza')\n",
    "f.draw()\n",
    "f.verbs[0].text, f.verbs[0].is_cat('learn'), \\\n",
    "    f.verbs[0].axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T06:14:06.918805Z",
     "start_time": "2020-04-05T06:14:06.888305Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'study'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T06:14:07.051528Z",
     "start_time": "2020-04-05T06:14:06.928449Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f.nouns[0].with_trans().sense\n",
    "f.nouns[0].with_trans()\n",
    "f.nouns[0].inherts('language|语言')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T06:14:07.119900Z",
     "start_time": "2020-04-05T06:14:07.057154Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 []\n",
      "1 estudiamos\n",
      "2 ['francés']\n"
     ]
    }
   ],
   "source": [
    "rs=f.walk_to(f.nouns[0])\n",
    "for i,node in enumerate(rs):\n",
    "    print(i, [n.text for n in node] if isinstance(node, tuple) else node.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T06:14:07.151241Z",
     "start_time": "2020-04-05T06:14:07.137070Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' ._ estudiamos(root) ._ francés(obj)'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_repr=lambda n: f\"{n.text}({n.dependency_relation})\"\n",
    "val_repr=lambda node: [node_repr(n) for n in node] if isinstance(node, tuple) else [node_repr(node)]\n",
    "' ._ '.join([','.join(val_repr(r)) for r in f.walk_to(f.nouns[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T06:14:07.178062Z",
     "start_time": "2020-04-05T06:14:07.158240Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AnalNode(dependency_relation='nsubj', entity=['O'], feats={'Case': 'Acc,Nom', 'Gender': 'Masc', 'Number': 'Plur', 'Person': '1', 'PronType': 'Prs'}, governor=2, index=1, lang='es', lemma='yo', name='nsubj', segments=[], text='Nosotros', tok=<JsonifyWordImpl index=1;text=Nosotros;lemma=yo;upos=PRON;xpos=PRON;feats=Case=Acc,Nom|Gender=Masc|Number=Plur|Person=1|PronType=Prs;governor=2;dependency_relation=nsubj>, upos='PRON', xpos='PRON')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.resolve_rels('*subj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T06:14:07.205742Z",
     "start_time": "2020-04-05T06:14:07.184961Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nosotros(nsubj) ._ estudiamos(root) ._ francés(obj)\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "def generic_paths(f):\n",
    "    subjs=f.resolve_rels('*subj')\n",
    "    start=subjs[0] if subjs else f\n",
    "    for n in chain(f.nouns, f.adjectives):\n",
    "        start.walk_to(n, verbose=True)\n",
    "\n",
    "generic_paths(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T06:14:07.291784Z",
     "start_time": "2020-04-05T06:14:07.212740Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('yo', 'I', '__1_Plur')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.rels('nsubj')[0].lemma, f.rels('nsubj')[0].axis, \\\n",
    "    f.rels('nsubj')[0].personal_pronoun_repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T06:14:07.314218Z",
     "start_time": "2020-04-05T06:14:07.300279Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'French'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.nouns[0].axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T06:14:07.329844Z",
     "start_time": "2020-04-05T06:14:07.320494Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'study'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T06:14:07.352436Z",
     "start_time": "2020-04-05T06:14:07.338877Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnalNode(engine='stanza', lang='es', name='_', sents='Nosotros estudiamos francés.', tok=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T14:11:11.897868Z",
     "start_time": "2020-04-06T14:11:11.815869Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root: 行き (行く, verb)\n",
      "|-- iobj: 12月 (12月, noun)\n",
      "|   |-- nmod: 年 (年, noun)\n",
      "|   |   +-- nummod: 2008 (2008, num)\n",
      "|   +-- case: に (に, adp)\n",
      "|-- iobj: 上海 (上海, propn)\n",
      "|   +-- case: に (に, adp)\n",
      "|-- aux: たいです (たい, aux)\n",
      "+-- punct: 。 (。, punct)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('行き',\n",
       " '2008年12月に',\n",
       " [('2008年12月', datetime.datetime(11, 4, 6, 22, 11, 11, 879709))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagas.nlu.anal import build_anal_tree, Doc\n",
    "from anytree.search import findall, findall_by_attr\n",
    "f=build_anal_tree('2008年12月に上海に行きたいです。', 'ja', 'stanza')\n",
    "f.draw()\n",
    "f.verbs[0].text, f.rels('iobj')[0].chunk, f.rels('iobj')[0].as_date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-06T14:21:19.344238Z",
     "start_time": "2020-04-06T14:21:19.294925Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12月\n",
      "年\n",
      "2008\n",
      "に\n",
      "上海\n",
      "に\n",
      "たい\n",
      "。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<rx.disposable.disposable.Disposable at 0x12ede1668>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import rx\n",
    "from rx import operators as ops\n",
    "def as_source(self):\n",
    "    return rx.of(*self.descendants)\n",
    "\n",
    "results=[]\n",
    "as_source(f).pipe(ops.do_action(lambda n: print(n.lemma)),\n",
    "                 ).subscribe(\n",
    "        on_next=lambda n: results.append(n),\n",
    "        on_error=lambda e: print(e),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T15:58:42.799345Z",
     "start_time": "2020-04-05T15:58:42.791106Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'inspector': 'extract_comps', 'provider': '', 'part': 'anal:', 'value': 'taidesu', 'delivery': 'slot', 'pattern': '_'}, {'inspector': 'extract_comps', 'provider': '', 'part': 'anal:', 'value': 'taidesu', 'delivery': 'slot', 'pattern': '_'}, {'inspector': 'extract_comps', 'provider': '', 'part': 'anal:', 'value': 'taidesu', 'delivery': 'slot', 'pattern': '_'}]\n"
     ]
    }
   ],
   "source": [
    "from sagas.nlu.inspector_extractor import ex_translit\n",
    "if ex_translit('', 'たいです', '', f.doc):\n",
    "    print(f.doc.resultset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T15:38:55.568297Z",
     "start_time": "2020-04-05T15:38:55.559239Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2008年12月に上海に行きたいです。\n"
     ]
    }
   ],
   "source": [
    "n=f.rels('iobj')[0]\n",
    "for node in n.iter_path_reverse():\n",
    "    if isinstance(node, Doc):\n",
    "        print(node.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-05T15:25:08.331615Z",
     "start_time": "2020-04-05T15:25:08.218950Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12月\n",
      "3 12月\n",
      "2 年\n",
      "1 2008\n",
      "4 に\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2008年12月に'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "from sagas.nlu.constants import delim\n",
    "iobj=f.rels('iobj')[0]\n",
    "print(iobj.text)\n",
    "for c in chain([iobj], iobj.descendants):\n",
    "    print(c.index, c.text)\n",
    "rs=sorted([(c.index, c.text) for c in chain([iobj], iobj.descendants)], key=lambda x:x[0])\n",
    "lang='ja'\n",
    "delim(lang).join([r[1] for r in rs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T06:28:37.773363Z",
     "start_time": "2020-04-07T06:28:37.766899Z"
    }
   },
   "outputs": [],
   "source": [
    "def as_type(n, dim):\n",
    "    dims=n.dims()\n",
    "    values = [d for d in dims if d['dim'] == dim]\n",
    "    return values\n",
    "def as_num(n):\n",
    "    vals=as_type(n, 'number')\n",
    "    if vals:\n",
    "        return vals[0]['value']['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T07:13:25.016877Z",
     "start_time": "2020-04-07T07:13:23.255398Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root: nueve (nueve, num)\n",
      "|-- nsubj: horario (horario, noun)\n",
      "|   +-- det: Nuestro (nuestro, det)\n",
      "|-- cop: es (ser, aux)\n",
      "|-- case: de (de, adp)\n",
      "|-- compound: cinco (cinco, num)\n",
      "|   +-- case: a (a, adp)\n",
      "+-- punct: . (., punct)\n",
      "es nueve\n",
      "Nuestro horario schedule\n",
      "nueve + a cinco\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('horario', 'schedule', 'ser', 9)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Text, Any, Dict, List, Union, Optional, Tuple\n",
    "from sagas.nlu.anal import build_anal_tree, Doc, AnalNode\n",
    "from anytree.search import findall, findall_by_attr\n",
    "from dataclasses import dataclass\n",
    "# \"我们的时间是从九点到五点。\"\n",
    "f=build_anal_tree('Nuestro horario es de nueve a cinco.', 'es', 'stanza')\n",
    "f.draw()\n",
    "\n",
    "@dataclass\n",
    "class Desc:\n",
    "    subj: AnalNode\n",
    "    aux: AnalNode\n",
    "    desc: AnalNode\n",
    "    nchks: List[AnalNode]\n",
    "    @property\n",
    "    def subj_spec(self) -> Text:\n",
    "        return self.subj.spec() if self.subj.is_noun() else '_'\n",
    "\n",
    "def node_or(nodels):\n",
    "    return nodels[0] if nodels else None\n",
    "def as_desc(f):\n",
    "    aux_ls=f.by_pos('AUX')\n",
    "    if aux_ls:\n",
    "        aux=aux_ls[0]\n",
    "        head=aux.parent\n",
    "        subjs=head.rels('nsubj', 'csubj')\n",
    "        nchks=head.rels('compound')\n",
    "        return Desc(subj=node_or(subjs),aux=aux, desc=head, nchks=nchks)\n",
    "\n",
    "for aux in f.by_pos('AUX'):\n",
    "    head=aux.parent\n",
    "    print(aux.text, head.text)\n",
    "    subjs=head.rels('nsubj', 'csubj')\n",
    "    if subjs:\n",
    "        print(subjs[0].chunk, subjs[0].spec() if subjs[0].is_noun() else '_')\n",
    "    nchks=head.rels('compound')\n",
    "    if nchks:\n",
    "        print(head.text, '+', nchks[0].chunk)\n",
    "\n",
    "# f.dims(), f.as_num()\n",
    "desc=as_desc(f)\n",
    "desc.subj.text, desc.subj_spec, desc.aux.lemma, desc.desc.as_num()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T13:25:20.365930Z",
     "start_time": "2020-04-07T13:25:20.351550Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SenseTree(root=SenseNode(role='sense', name='us', children=[SenseNode(role='', name='human|人', children=[SenseNode(role='PersonPro', name='1stPerson|我', children=[]), SenseNode(role='quantity', name='mass|众', children=[])])]), inherits=[SenseNode(role='', name='human|人', children=[SenseNode(role='PersonPro', name='1stPerson|我', children=[]), SenseNode(role='quantity', name='mass|众', children=[])])], roles={'PersonPro': {'1stPerson|我'}, 'quantity': {'mass|众'}, 'sense': {'us'}}, word=SenseWord(definition='{human|人:PersonPro={1stPerson|我},quantity={mass|众}}', en_grammar='pron', zh_grammar='pron', en_word='us', zh_word='咱们', id='199921', syns=[SenseSyn(id='011344', text='阿拉'), SenseSyn(id='012588', text='俺们'), SenseSyn(id='012589', text='俺们'), SenseSyn(id='018067', text='辈'), SenseSyn(id='018068', text='辈'), SenseSyn(id='019738', text='敝'), SenseSyn(id='104068', text='劳资'), SenseSyn(id='107599', text='两人'), SenseSyn(id='109914', text='流氓无产者'), SenseSyn(id='136243', text='群氓'), SenseSyn(id='136985', text='人'), SenseSyn(id='136986', text='人'), SenseSyn(id='137050', text='人丁'), SenseSyn(id='137165', text='人口'), SenseSyn(id='137166', text='人口'), SenseSyn(id='137252', text='人们'), SenseSyn(id='137253', text='人们'), SenseSyn(id='137254', text='人们'), SenseSyn(id='137336', text='人群'), SenseSyn(id='142692', text='上下')]))]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagas.zh.hownet_helper import SenseTree, get_trees\n",
    "get_trees('us')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T07:13:50.888419Z",
     "start_time": "2020-04-07T07:13:49.583216Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('horario', 'schedule', 'ser', 9)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagas.nlu.anal import build_anal_tree, Doc, AnalNode\n",
    "f=build_anal_tree('Nuestro horario es de nueve a cinco.', 'es', 'stanza')\n",
    "desc=f.as_desc()\n",
    "desc.subj.text, desc.subj_spec, desc.aux.lemma, desc.desc.as_num()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T08:29:15.473268Z",
     "start_time": "2020-04-07T08:29:15.444749Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root: estudiamos (estudiar, verb)\n",
      "|-- nsubj: Nosotros (yo, pron)\n",
      "|-- obj: idioma (idioma, noun)\n",
      "+-- punct: . (., punct)\n",
      "estudiamos estudiamos\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(AnalNode(dependency_relation='nsubj', entity=['O'], feats='Case=Acc,Nom|Gender=Masc|Number=Plur|Person=1|PronType=Prs', governor=1, index=2, lang='es', lemma='yo', name='nsubj', segments=[], text='Nosotros', tok=<JsonifyWordImpl index=2;text=Nosotros;lemma=yo;upos=PRON;xpos=PRON;feats=Case=Acc,Nom|Gender=Masc|Number=Plur|Person=1|PronType=Prs;governor=1;dependency_relation=nsubj>, upos='PRON', xpos='PRON'),)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagas.nlu.anal import build_anal_tree, Doc, AnalNode\n",
    "f=build_anal_tree('estudiamos Nosotros idioma.', 'es', 'stanza')\n",
    "f.draw()\n",
    "print(f.text, f.verbs[0].text)\n",
    "verb=f.verbs[0]\n",
    "verb.rels('nsubj', 'csubj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T12:13:48.934465Z",
     "start_time": "2020-04-07T12:13:48.767742Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root: Apa (apa, pron)\n",
      "|-- amod: murah (murah, adj)\n",
      "|   |-- nsubj: yang (yang, pron)\n",
      "|   +-- advmod: lebih (lebih, adv)\n",
      "+-- punct: ? (?, punct)\n",
      "1 yang\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('amod.nsubj', 'Desc')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagas.nlu.anal import build_anal_tree, Doc, AnalNode\n",
    "f=build_anal_tree('Apa yang lebih murah?', 'id', 'stanza')\n",
    "f.draw()\n",
    "# f.resolve_rels('*/*subj')\n",
    "print(len(f.subjs), f.as_subj().subj.text)\n",
    "subj=f.as_subj().subj\n",
    "subj.path_to(f), type(f.model()).__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T09:22:05.489433Z",
     "start_time": "2020-04-07T09:22:05.475398Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['amod', 'nsubj']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path=[n.deprel for n in subj.walk_to(f)[0]]\n",
    "path.reverse()\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T13:40:01.932808Z",
     "start_time": "2020-04-07T13:39:59.868653Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root: фрукт (фрукт, noun)\n",
      "|-- nsubj: Яблоко (яблоко, noun)\n",
      "|   +-- punct: - (-, punct)\n",
      "|-- cop: это (это, pron)\n",
      "|-- amod: здоровый (здоровый, adj)\n",
      "+-- punct: . (., punct)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1,\n",
       " 'Яблоко',\n",
       " 'nsubj',\n",
       " ['cop', 'amod'],\n",
       " 'Desc',\n",
       " {'computer|电脑', 'fruit|水果', 'tool|用具', 'tree|树'},\n",
       " 'apple')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagas.nlu.anal import build_anal_tree, Doc, AnalNode\n",
    "f=build_anal_tree('Яблоко - это здоровый фрукт.', 'ru', 'stanza')\n",
    "f.draw()\n",
    "# f.resolve_rels('*subj')\n",
    "subj=f.subjs[0]\n",
    "len(f.subjs), subj.subj.text, subj.subj.path_to(f), \\\n",
    "    subj.modifier_names, type(f.model()).__name__, \\\n",
    "    f.model().target.types, \\\n",
    "    f.model().target.spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T13:40:18.945649Z",
     "start_time": "2020-04-07T13:40:18.930870Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['apple.n.01'], ['apple'], {'computer|电脑', 'fruit|水果', 'tool|用具', 'tree|树'})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target=f.model().target\n",
    "target.synsets(), target.syn_names(), target.spec_types()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T12:41:04.671222Z",
     "start_time": "2020-04-07T12:41:03.427533Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root: Karpet (karpet, noun)\n",
      "|-- nmod: kantor (kantor, noun)\n",
      "|   |-- case: di (di, adp)\n",
      "|   |-- det: saya (saya, pron)\n",
      "|   +-- amod: abu-abu (abu, adj)\n",
      "+-- punct: . (., punct)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Karpet', ['nmod', 'nmod.amod'], 'Phrase')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagas.nlu.anal import build_anal_tree, Doc, AnalNode\n",
    "f=build_anal_tree('Karpet di kantor saya abu-abu.', 'id', 'stanza')\n",
    "f.draw()\n",
    "f.as_noun_phrase().head.text, f.as_noun_phrase().modifier_names, \\\n",
    "    type(f.model()).__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T12:41:07.894276Z",
     "start_time": "2020-04-07T12:41:07.689979Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rug\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('carpet', {'tool|用具'})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f.model().target.spec())\n",
    "target=f.model().target\n",
    "target.axis, target.types"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
