{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T08:00:29.240316Z",
     "start_time": "2020-06-24T08:00:25.092529Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "import torch\n",
    "from transformers.tokenization_bert_japanese import BertJapaneseTokenizer\n",
    "from transformers.modeling_bert import BertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T08:02:16.121348Z",
     "start_time": "2020-06-24T08:02:08.080242Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = BertJapaneseTokenizer.from_pretrained(\"cl-tohoku/bert-base-japanese-whole-word-masking\")\n",
    "model = AutoModelWithLMHead.from_pretrained(\"cl-tohoku/bert-base-japanese-whole-word-masking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T08:02:41.293867Z",
     "start_time": "2020-06-24T08:02:41.281621Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    2,   872,  2311,   309,    12,     4,     5,   401, 13423,    11,\n",
      "            46, 28457, 11665,     8,     3]])\n",
      "['[CLS]', '青', '葉', '山', 'で', '[MASK]', 'の', '研', '究', 'を', '##して', '##い', '##ます', '。', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(f'''\n",
    "    青葉山で{tokenizer.mask_token}の研究をしています。\n",
    "''', return_tensors='pt')\n",
    "print(input_ids)\n",
    "print(tokenizer.convert_ids_to_tokens(input_ids[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T08:02:56.485193Z",
     "start_time": "2020-06-24T08:02:56.476139Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "masked_index = torch.where(input_ids == tokenizer.mask_token_id)[1].tolist()[0]\n",
    "print(masked_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T08:03:03.684939Z",
     "start_time": "2020-06-24T08:03:03.483248Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] 青 葉 山 で 学問 の 研 究 をしています 。 [SEP]\n",
      "[CLS] 青 葉 山 で 武術 の 研 究 をしています 。 [SEP]\n",
      "[CLS] 青 葉 山 で 武芸 の 研 究 をしています 。 [SEP]\n",
      "[CLS] 青 葉 山 で 修行 の 研 究 をしています 。 [SEP]\n",
      "[CLS] 青 葉 山 で 剣術 の 研 究 をしています 。 [SEP]\n"
     ]
    }
   ],
   "source": [
    "result = model(input_ids)\n",
    "pred_ids = result[0][:, masked_index].topk(5).indices.tolist()[0]\n",
    "for pred_id in pred_ids:\n",
    "    output_ids = input_ids.tolist()[0]\n",
    "    output_ids[masked_index] = pred_id\n",
    "    print(tokenizer.decode(output_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T11:09:43.880877Z",
     "start_time": "2020-06-24T11:09:20.658659Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "感 0.3632276654243469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiaofeiwu/miniconda3/envs/bigdata/lib/python3.7/site-packages/ipykernel_launcher.py:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, AlbertForMaskedLM\n",
    "import torch\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "pretrained = 'voidful/albert_chinese_base'\n",
    "tokenizer = BertTokenizer.from_pretrained(pretrained)\n",
    "model = AlbertForMaskedLM.from_pretrained(pretrained)\n",
    "\n",
    "inputtext = \"今天[MASK]情很好\"\n",
    "\n",
    "maskpos = tokenizer.encode(inputtext, add_special_tokens=True).index(103)\n",
    "\n",
    "input_ids = torch.tensor(tokenizer.encode(inputtext, add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "outputs = model(input_ids, masked_lm_labels=input_ids)\n",
    "\n",
    "loss, prediction_scores = outputs[:2]\n",
    "logit_prob = softmax(prediction_scores[0, maskpos]).data.tolist()\n",
    "predicted_index = torch.argmax(prediction_scores[0, maskpos]).item()\n",
    "predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n",
    "print(predicted_token,logit_prob[predicted_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T11:10:14.303794Z",
     "start_time": "2020-06-24T11:10:14.297799Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "感 0.3632276654243469\n"
     ]
    }
   ],
   "source": [
    "predicted_tokens = tokenizer.convert_ids_to_tokens([predicted_index])\n",
    "for predicted_token in predicted_tokens:\n",
    "    print(predicted_token,logit_prob[predicted_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T11:17:03.770024Z",
     "start_time": "2020-06-24T11:17:03.671428Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': '[CLS] 今 天 感 情 很 好 [SEP]',\n",
       "  'score': 0.3632276654243469,\n",
       "  'token': 2697},\n",
       " {'sequence': '[CLS] 今 天 缘 情 很 好 [SEP]',\n",
       "  'score': 0.053004853427410126,\n",
       "  'token': 5357},\n",
       " {'sequence': '[CLS] 今 天 好 情 很 好 [SEP]',\n",
       "  'score': 0.041060544550418854,\n",
       "  'token': 1962},\n",
       " {'sequence': '[CLS] 今 天 人 情 很 好 [SEP]',\n",
       "  'score': 0.0362703762948513,\n",
       "  'token': 782},\n",
       " {'sequence': '[CLS] 今 天 恋 情 很 好 [SEP]',\n",
       "  'score': 0.03572859615087509,\n",
       "  'token': 2605}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "nlp=pipeline('fill-mask', model=model, tokenizer=tokenizer)\n",
    "nlp('今天[MASK]情很好')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
